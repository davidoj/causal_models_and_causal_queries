
\section{Key Questions}

\section{Causal Models}

\subsubsection{Definition of Causal Models}

\begin{question}
    Do the major examples of causal models in the literature satisfy Definition \ref{def:causal_models}?
    \begin{itemize}
        \item Causal Bayesian Networks
        \item Structural Causal Models
        \item Potential Outcomes/Rubin Causal Model
        \item Marginal models
    \end{itemize}
\end{question}

\begin{question}
    Are the major examples of causal models in the literature special cases of probability distributions with the "exorcism" assumption (Definition \ref{def:exorcism})?
    \begin{itemize}
        \item Causal Bayesian Networks
        \item Structural Causal Models
        \item Potential Outcomes/Rubin Causal Model
        \item Marginal models
    \end{itemize}
\end{question}

\begin{question}
    Is it possible to use markov kernels rather than policy functions to define policy based causality?
\end{question}

\begin{question}
    Is the exorcism assumption necessary for causal reasoning (Definition \ref{def:exorcism})?
\end{question}

\begin{question}
    What is the appropriate line of reasoning to take if, in Definition \ref{def:exorcism}, we allow $\mathcal{F}\subset A$?
\end{question}

\subsubsection{Relationships between types of causal models}

\begin{question}
    Is there an equivalence between functions with sources of noise for inputs and Markov kernels?
\end{question}

\begin{question}
    One feature of structural causal models is the possibility to derive deterministic maps by substituting constants for the noise variables $u_i$. This could be seen as a generalisation of interventions from operations that replace the right hand side of an assignment with a constant to an operation that makes a more general modification to the right hand side of an assignment.
    
    What is the set of general interventions on an SCM that preserve the Markovian property?
\end{question}

\begin{question}
    What is the precise relationship between the key assumptions in potential outcomes causality (ignorability, common support) and key assumptions identified for policy causality (exorcism, complete interventional projections)?
\end{question}

\subsubsection{Causal models vs probability distributions}

\begin{question}
    Pearl claims there are fundamental differences between causal and probabilistic models \cite{pearl_causality:_2009}. Does policy based causality effectively refute this claim?
\end{question}


\subsubsection{Causal models vs other kinds of models}

\begin{question}
    What is the relationship between general/Markovian causal models and other system models, particularly where interaction with the system is important? 
    
    Relationship could mean: does one type of model a subset of another? Is there some operation that generates one type of model given another?
    \begin{itemize}
        \item First order state space models
        \item Markov Decision Processes
    \end{itemize}
\end{question}

\subsubsection{Weakening causal assumptions}

\begin{question}
    Given a structural causal model, policy based causality doesn't distinguish in type between a policy and a regular node - both are functions of input variable and independent noises. Does this yield a natural spectrum for soft to hard interventions, where soft interventions are "the original function" and hard interventions impose constant functions at the policy node?
\end{question}

\begin{question}
    Given the above spectrum of soft to hard interventions, what options are there for interpolating between these points?
\end{question}

\begin{question}[Intervention cascade]\label{q:intervention_cascade}
    Given the ability to perform a hard intervention on a particular node, does this raise the possibility of performing soft interventions on a number of other nodes?
\end{question}

% \subsubsection{Markovian causal models}

% \begin{question}
%     Is there an appropriate way to define an "approximately Markovian" causal model?
%     Points to consider:
%     \begin{itemize}
%         \item Are there operations we can perform on data generated by a Markovian system that will yield an approximately Markovian system? Example operations: forgetting data for some variables, averaging data over time or over repeated instances.
%         \item Is there a "mathematically neat" way to define approximate Markovianity?
%     \end{itemize}
% \end{question}

\subsection{Causal Inference Problems}

\begin{question}[Generalisation of interventional trials]
    See Question \ref{q:intervention_cascade}.
    
    Motivation: RCTs often estimate the effects of composite interventions in particular contexts, so interpretation is unclear. However, they also reliably identify causal effects, which distinguishes RCT results from any old dataset.
    
    Question: Under what conditions can a *set* of RCT results be generalised? Is there enough causal information in an RCT to permit a "statistical learning theory" type of result for RCT generalisation, or is the problem of generalising RCTs itself limited by nonidentifiability issues?
\end{question}

\begin{question}\label{q:causal_queries}
    What are the key kinds of causal queries? A very preliminary list:
    \begin{itemize}
        \item Control/prediction: how would a system behave if intervention $I$ were applied?
        \item Attribution: what is responsible for the observation of outcome $v$?
        \item Latent variables: identifying latent variables causally responsible for observed data
        \item Causal structure: identifying how observed variables are causally related to one another
    \end{itemize}
\end{question}

\begin{question}
    Detecting latent variables has a clear connection to dimensionality reduction \cite{kummerfeld_causal_2016}. As a general question, how does \emph{causal} latent variable detection differ from other forms of dimension reduction?
    
    As a more specific question, is there a particular form of loss function that is, implicitly or explicitly, assumed in causal latent variable detection? 
\end{question}

\begin{question}\label{q:causal_query_difficulty}
    How should the difficulty of a causal query be measured?
    Some possibilities:
    \begin{itemize}
        \item Observational sample complexity
        \item Interventional sample complexity
    \end{itemize}
\end{question}

\begin{question}
    Is it possible to define a generic set of elements that constitute a causal inference query? For example, a control query might require:
    \begin{itemize}
        \item Outcome/objective
        \item Set of allowed interventions
        \item Set of observations
        \item Hypothesis class
        \item Assumptions
        \item Data
    \end{itemize}
\end{question}

\begin{question}
    Causal queries typically employ assumptions over and above the assumptions made for statistical queries. Are additional assumptions always necessary?
    
    More precisely: given a causal model $M$ for which the class $\mathcal{P}$ of distributions satisfies statistical learnability assumptions (clarification pending), what characterises causal queries that are unresolvable without further assumptions?
\end{question}

\begin{question}\label{q:query_set_of_models}
    Given a causal query (pending definition) and the assumption of a Markovian causal model, does the query induce equivalence classes of causal models? Does this depend on the type of query?
\end{question}

\begin{question}
    Can two identical causal models (Definition \ref{def:causal_models}) with different side information (definition pending) give different answers to a causal query (definition pending)?
\end{question}

\begin{question}
    What are key features in a taxonomy of causal inference problems that aims to group problems by which approaches to solving the problem may/may not work? Do the objects identified in Definition \ref{def:causal_models} - $\mathbf{V}$, $\mathcal{I}$, $\mathcal{P}$ play important roles in such a taxonomy?
\end{question}

\begin{question}
    Given a causal bayesian network $M$ with targets $Y$, other observables $X$ and interventions $\mathcal{I}$ and cost $C:\mathcal{I}\times Y\to\mathbb{R}$, are there control strategies possible with $M$ that may be superior to control strategies possible if only $P(Y|I)$ is known for all $I\in\mathcal{I}$?
\end{question}

\subsection{Causal Discovery}

Causal discovery describes any method of learning a set of Markovian causal models that might describe the causal relationships between variables in a dataset.

\begin{question}
    To what extent have additive noise models been extended to Markov kernels featuring other types of noise? To what extent can they be extended?
\end{question}

\begin{question}
    Is it correct to consider queries about causal structures instrumental queries in service of other aims? Alternatively, should causal structures be added to the list in Question \ref{q:causal_queries}?
\end{question}

Many algorithms for causal structure discovery do not resolve whether $X$ and $Y$ are confounded by an unobserved $Z$ or not. On the other hand, the answer many conceivable causal queries will depend on whether two variables are confounded or directly causally related. The next questions focus on whether structural identification can help with causal queries.

\begin{question}\label{q:discovery_set_of_models}
    A structure discovery algorithm will typically output some class $\mathcal{C}$ of causal models. In some cases these classes are well-defined, for example Markov Equivalence Classes. In some cases it is not so clear - algorithms that cannot detect latent confounders are usually introduced with the assumption that no such confounders exist. However, it is also possible to view them as outputting a large class of causal models that contains many models with latent confounders and some without.
    
    The question here is what classes of causal models are output by the various structure learning algorithms?
\end{question}

\begin{question}
    Considering the model sets in \ref{q:query_set_of_models} and \ref{q:discovery_set_of_models}, when is it possible for the output of a structure discovery algorithm to facilitate answering a causal query - for example, by reducing the query to one that is easier on a metric of difficulty (question \ref{q:causal_query_difficulty}).
\end{question}

\begin{question}
    Which causal discovery algorithms require the assumption of faithfulness?
    \begin{itemize}
        \item PC and IC definitely do
        \item Bayesian score based (e.g. Greedy Equivalence Search) I'm not sure
        \item Additive noise models, information geometric definitely don't
        \item Latent factor detection (BPC, FOFC) - I'm not sure \cite{kummerfeld_causal_2016}
    \end{itemize}
\end{question}

\begin{question}
    What is the relationship between $\lambda$ in $\lambda$-faithfulness and sample complexity of PC-type algorithms?
\end{question}

\begin{question}
    Are there weakenings of faithfulness or $\lambda$-faithfulness, and do these allow for consistency results of their own?
    \begin{itemize}
        \item Some types of faithfulness violations have testable implications, so only some types of faithfulness need to be assumed \cite{ramsey_adjacency-faithfulness_2012}
        \item Some types of faithfulness violations could be benign (e.g. violated faithfulness in $X\to Y$) \cite{peters_structural_2013}
        \item The degree to which faithfulness violations impact the answer to a causal query might scale with the number of "non-transparent" conditional independences 
    \end{itemize}
\end{question}

\begin{question}\label{q:volume_unfaithful}
    Is it possible to lower bound the volume of unfaithful distributions for a set of probability distributions $\mathcal{P}_G$ with parametrisation $\mathbf{a}_G$ that are Markovian to an arbitrary graph $G$? \cite{uhler_geometry_2013}
\end{question}

\begin{question}
    Can entropy-based constraints simplify the analysis of sets of faithful distributions in Question \ref{q:volume_unfaithful} (I don't presently understand what entropy-based constraints are, so this question might make no sense. I just recall a comment that entropy based constraints can be easier to work with than geometry of algebraic varieties).
\end{question}

Both the faithfulness assumption and additive noise model causal discovery identify a "contrast function" $C(P):\mathcal{P}\to\mathbb{R}$ of a probability distribution $P$ that, given a measure $\mu_G$ over $\mathcal{P}$ for each CBN $G$, takes generic values for to some CBNs $\mathcal{G}^*$ and nongeneric values for all others $\mathcal{G}^{*C}$. That is, $\mu_{G^*}(C(P))>0$, and $\mu_{G'}(C(P))=0$ for any $G'\in\mathcal{G}^{*C}$.

\begin{question}\label{q:generalised_genericity}
    These genericity conditions hold for a general class of measures $\mu_G$ - for example, if a distribution $P$ is parametrised by $\{a_i\}$ for a graph $G$, then the genericity conditions might hold for any continuous prior over $\{a_i\}$.
    
    However, to get uniform consistency results, we need to allow for some slack around the value of $C(P)$, and consequently need to shift from "non-transparent" probability distributions having measure 0 under $\mu_G$ to having small measure under $\mu_G$.
    
    For what class of measures can we conclude from $\mu_G(C(P)=c_0)=0$ and $|C(\hat{P})-c_0|<\delta$ that $\mu_G(C(\hat{P})\in B_\delta (c_0)) < \epsilon$? Does this depend strongly on $C$?
    
    $B_\delta(x)$ is a ball of radius $\delta$ around $x$.
\end{question}
    
\begin{question}
    Are there any general properties that contrast functions must satisfy?
\end{question}

\begin{question}
    Is there a method to generate contrasts $C$? See \cite{besserve_group_2017} for a discussion of using group transformations for generating measures $\mu_G$.
\end{question}
