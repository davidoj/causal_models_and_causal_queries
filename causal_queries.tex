\section{Causal Policies}

\begin{definition}[Causal optimization problem]\label{def:2s_copt_prob}
A causal optimization problem has 5 elements $\langle V, \Phi, I, A, C\rangle$. $V$, $I$ and $A$ are disjoint (but not independent) random variables, and $\phi$ is a variable taking values from some set of Markov kernels $\Phi\in\{\phi:A\to  \Delta I\}$. $C:\Delta(V\times I) \to \mathbb{R}$ is a cost function. Given these elements, and the possibility of generating an arbitrary number of i.i.d. samples for a particular choice of $\phi_{obs}\in\Phi$, the task is to find $\phi^*\in \Phi$ minimising $C(P(V, I|\phi))$.
\end{definition}

\begin{remark}
In this version of the problem, sample complexity and training cost are neglected. A more general version would approximate a reinforcement learning problem, which would involve some kind of exploration-exploitation tradeoff.
\end{remark}

\begin{definition}[Causal Identifiability]\label{def:causal_ident}
Given the causal optimization problem $\langle V, \Phi, I, A, C\rangle$ and a set of test policies $\Phi_T$, the problem is identifiable if there exists $\phi_{obs}\in\Phi_T$ such that for all $\phi\in\Phi$ the distribution $P(I,V|\Phi=\phi)$ can be consistently estimated from i.i.d. samples under $\phi_{obs}$.
\end{definition}

Clearly, if a causal optimization problem is identifiable, then it is possible to find an optimal $\phi^*\in \Phi$. The converse is not generally true; for a trivial example, if the cost function is constant then identifiability is not needed as all policies are optimal.

\subsection{Existing approaches to identifiability}

In the following, unless otherwise mentioned, assume $I,A,V\in \{0,1\}$ and $C(P(I\times V)) = \mathbb{E}[V]$

\subsubsection{Potential Outcomes}

Define the constant policies $\pi_0:\mu_I\mapsto \delta(I)$ and $\pi_1:\mu_I\mapsto \delta(1-I)$ where $\delta(\cdot)$ is the Dirac delta function.

The potential outcomes approach argues that identifiability holds provided the following two assumptions are met for all $x\in X\subset A$, $i\in I$: \cite{rubin_causal_2005} \cite{sontag_causal_nodate}
\begin{enumerate}
    \item Ignorability: \[P(V|X=x,\Phi=\pi_i, I=i) = P(V|X=x,I=i,\Phi=\phi_{obs})\]
    \item Common support: \[P(I=i|X=x,\Phi=\phi_{obs})>0\]
\end{enumerate}
Where $X$ is an observed set of covariates.

These assumptions only cover optimization problems where $\Phi\in \{\pi_i|i\in I\}$. If $\Phi$ is in a larger class of functions, we must strengthen the assumption of ignorability:

\begin{enumerate}
    \item Extended ignorability: for all $\phi\in\Phi$ \[P(V|X=x,\Phi=\phi, I=i) = P(V|X=x,I=i,\Phi=\phi_{obs})\]
\end{enumerate}

Even when these assumptions are met, there is an ambiguity over how to identify the effect of a policy $\phi$. Consider the following two cases, and assume extended ignorability:

\begin{center}
\begin{tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white ,
draw , text=blue , minimum width =1 cm}]
\node[state] (B) [right] {$V$};
\node[state] (A) [left = 3cm of B] {$I$};
\node[state] (C) [above right = 1cm and 1.5cm of A] {$X$};
\path (A) edge [] node[above] {} (B);
\draw (C) -- (A);
\draw (C) -- (B);
\node[state] (D) [right = 4cm of B] {$I$};
\node[state] (E) [right = 1.5cm of D] {$X$};
\node[state] (F) [right = 1.5cm of E] {$V$};
\path (A) edge [] node[above] {} (B);
\draw (C) -- (A);
\draw (C) -- (B);
\draw (D) -- (E);
\draw (E) -- (F);
\end{tikzpicture}
\end{center}


In the first case,
\begin{align}
    P(V|\phi)&=\sum_{I,X} P(X) P(I|X,\phi) P(V|I,X,\phi)\\
             &=\sum_{I,X} \phi(X)(I) P(X)  P(V|I,X,\phi_{obs}) \label{eq:hc_xcov}
\end{align}
while in the second case
\begin{align}
    P(V|\phi)&=\sum_I P(I|\phi) P(V|I,\phi) \\
             &=\sum_I \phi(\varnothing)(I) P(V|I,\phi_{obs})\\
             &=\sum_{I,X} \phi(\varnothing)(I) P(X|I,\phi_{obs}) P(V|I,X,\phi_{obs}) \label{eq:int_xcov}
\end{align}
Equations \ref{eq:hc_xcov} and \ref{eq:int_xcov} are not in general equal.

\subsubsection{Causal Bayesian Networks}

For Causal Bayesian Networks, we will identify the intervention $do(I=i)$ with the constant policy $\pi_i$.

For some graph $G$ and some node $I$, denote the graph deleting all outgoing edges of $I$ by $G_{\underline{I}}$ and the graph obtained by deleting all incoming edges to $I$ as $G_{\overline{I}}$.

Assume that with respect to some graph $G$, $P$ satisfies the conditions of a Causal Bayesian Network (Definition \ref{def:CBN}) for $P(V|do(I=i)=P(V|\pi_i)$, $\forall i\in I$. Given this assumption, a key criterion for identifiability in Causal Bayesian Networks is the ``back-door'' criterion:

If $X\subset A$ are observed, then $I\perp_{G_{\underline{I}}} V|X$

There is also a ``front-door'' criterion, which depends on a more complex graph structure.

The back-door criterion implies ignorability \cite{pearl_causality:_2009}. Furthermore, a CBN does not suffer from the covariate adjustment ambiguity above.

The common support assumption doesn't seem to be mentioned much in the CBN literature, but it is also required for identifiability as it has been defined in \ref{def:causal_ident}. In particular, it may not be possible to identify the effects of all policies of interest. It's easy to verify that the probability distribution generated by $\Phi=\pi_1$, $V=I$ satisfies the above conditions for the graph

\begin{center}
\begin{tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white ,
draw , text=blue , minimum width =1 cm}]
\node[state] (B) [right] {$V$};
\node[state] (A) [left = 3cm of B] {$I$};
\path (A) edge [] node[above] {} (B);
\end{tikzpicture}
\end{center}

However, this doesn't allow for $P(V|\pi_0)$ to be consistently estimated - $P(V|I=0,\Phi=\pi_1)$ asks us to condition on a contradiction.

It is straightforward to define a distribution under a conditional intervention using a CBN: $P(V|\Phi=\phi)=\sum_X P(V|X,\Phi=\phi(x)) P(X)$. This amounts to a modification of Definition \ref{def:CBN} where we extend the parental adjustment assumption to cover $do$ interventions with arguments that may depend on other nodes in the graph. There are reasonable situations in which this extension may not hold, even if the original assumption holds (see section \ref{sssec:SUTVA} below).

\subsubsection{Untestability of key assumptions}

Given the ``one-kernel'' rule, we are restricted to knowing at most one of $P(V|X=x,\Phi=\phi,I=0)$ and $P(V|X=x, I=0, \Phi=\phi_{obs})$ if $\phi\neq \phi_{obs}$. Thus, we cannot in general test whether these distributions are equal, as the ignorability assumption asserts. 

Furthermore, it is may not be intuitively obvious when the assumption holds. A common practical approach is to make $X$ a very large set of covariates. It is not obvious when $X$ is a large enough set of covariates, nor is it obvious if the covariates included should be adjusted for (as in the first example above) or not adjusted for (as in the second).

The back-door criterion is also untestable for general $\phi_{obs}$. No property of the distribution $P(V,I,X)$ can rule out the existence of some unmeasured $X'$ such that $X'$ is a common ancestor of $V$ and $I$, which would create an additional back-door path.

I also propose a pair of assumptions that entail both ignorability and the back-door criterion. Like the potential outcomes approach, they allow for causal effects to be defined without assuming that the full set of random variables can be modeled as a CBN. Unlike the potential outcomes approach, these assumptions are not ambiguous over how to adjust for covariates. They are sufficient and not necessary conditions:

\begin{enumerate}
    \item Known domain: Every $\phi\in\Phi\cup \Phi_T$ has domain $A$, and $A$ is observed
    \item Policy is not intrinsically relevant: $P(V|A,I,\Phi)=P(V|A,I)$ for all $a\in A$, $i\in I$, $\phi\in \Phi$
\end{enumerate}

\subsubsection{Interactions}\label{sssec:SUTVA}

A challenge for the CBN framework of causal inference is situations where the effects of separate intervention decisions may interact.

Suppose a vaccine for a contagious disease is being tested on two individuals who live in the same home. The probability of infection $D$ depends on both the vaccination decision $V$ and the presence of another infected person $P$:

\begin{table}[]
    \centering
    \begin{tabular}{c|c|c}
        & $P=0$ & $P=1$ \\
         \hline
        $V=0$ & 0.5 & 1 \\
        $V=1$ & 0.2 & 0.4
    \end{tabular}
    \caption{Probability of disease $D$ by vaccination and presence of infection}
    \label{tab:vaccination_interaction}
\end{table}

For simplicity's sake, we will posit there are two opportunities for infection, both governed by the probabilities in the above table. At the first infection opportunity, neither housemate is infected. However, the presence of infection is only measured once, at the end of the second period.

If the decision to vaccinate $\Phi$ has domain $\varnothing$, we could naively model the situation with the following graph for each individual:

\begin{center}
\begin{tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white ,
draw , text=blue , minimum width =1 cm}]
\node[state] (A) [left] {$V$};
\node[state] (B) [right = 3cm of A] {$D$};
\path (A) edge [] node[above] {} (B);
\end{tikzpicture}
\end{center}

If $\Phi$ is restricted to constant policies $\pi_0:V\mapsto 0$ and $\pi_1:V\mapsto 1$, the parental adjustment condition must hold for the above graph, as $V=0\implies \phi=\pi_0$ and so $P(D|V=0)=P(D|\Phi=\pi_0)$. However, this is not true for general policies. If the unobserved housemate is vaccinated, then we have
\begin{align}
    P(D|V=0) &= 0.5 + (1-0.5)(0.2*0.5+0.4*1) \\
             &= 0.75 \\
    P(D|\Phi=\pi_0) &= 0.5 + (1-0.5)(0.5*0.5 + 0.5*1) \\
            &= 0.875 \\
            &\neq P(D|V=0)
\end{align}

Another naive attempt would fail due to containing a cycle. Here $V^i$ ($D^i$) are the vaccination (infection) states of the $i$th housemate:

\begin{center}
\begin{tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white ,
draw , text=blue , minimum width =1 cm}]
\node[state] (A) [left] {$V^1$};
\node[state] (D) [below = 2cm of A] {$V^2$};
\node[state] (B) [right = 3cm of A] {$D^1$};
\node[state] (C) [right = 3cm of D] {$D^2$};
\draw (A) -- (B);
\draw (D) -- (C);
\draw[<->] (B) -- (C);
\end{tikzpicture}
\end{center}

A working CBN model is possible, but it demands modelling the dynamics of the system which may introduce many degrees of freedom and not always be necessary. Here $D^1_i$ is the infection state of housemate 1 at time $i$:

\begin{center}
\begin{tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ circle ,top color =white ,
draw , text=blue , minimum width =1 cm}]
\node[state] (A) [left] {$V^1$};
\node[state] (F) [below = 2cm of A] {$V^2$};
\node[state] (B) [right = 3cm of A] {$D^1_1$};
\node[state] (C) [right = 3cm of F] {$D^2_1$};
\node[state] (D) [right = 3cm of B] {$D^1_2$};
\node[state] (E) [right = 3cm of C] {$D^2_2$};
\draw (A) -- (B);
\draw (F) -- (C);
\draw (B) -- (E);
\draw (C) -- (D);
\draw (B) -- (D);
\draw (C) -- (E);
\end{tikzpicture}
\end{center}

The assumption that these kind of interactions don't occur is discussed in the Potential Outcomes literature as part of the "stable unit treatment value assumption" (SUTVA).

\textbf{Question: } How does the ``policy-intrinsic-irrelevance'' assumption behave when there might be interactions of this form?




% \begin{definition}[Interventional projection]
% Define an equivalence relation $\sim$ on $A$ such that $a\sim a'$ iff $P(V|a,i)=P(V|a',i)$ for all $i\in I$. Denote by $E_a$ the equivalence class of $a\in A$ induced by $\sim$, and $\mathbf{E}_A$ the set of such equivalence classes. The interventional projection of $A$ is the map $g:A\to\mathbf{E}_A$. 
% \end{definition}

% \begin{definition}[Complete interventional projection]
% An interventional projection is complete with respect to a policy $f$ if for every $i\in I$ and $E_a\in\mathbf{E}_A$ there exists $a\in E_a$ such that $f(a)=i$.
% \end{definition}

% \begin{example}[Complete interventional projection]
% Suppose $A=X\times M$ where $X$ is a set of observed covariates and $M$ is a noise where $V\CI M | I$. Then $g(x,\mu)=x$ is an interventional projection of $A$, and for any $f$ where for all $i,x$ there exists a $\mu\in M$ such that $f(x,\mu)=i$, $g$ is a complete interventional projection.
% \end{example}

% \begin{theorem}[Complete interventional projection implies policy identifiability]
% Given a causal optimisation problem $\langle P, V, \mathcal{F}, I, A, \mathcal{C}\rangle$, if there is some $f\in\mathcal{F}$ such that there is a complete interventional projection $g:A\to\mathbf{E}_A$, then $P$ is identifiable.
% \end{theorem}

% \begin{proof}
% Take $f\in\mathcal{F}$ to be a policy with a complete interventional projection $g$. Given arbitrary $a\in A$ and $i\in I$, we have $P(V|a,i)=P(V|a',i)$ for any $a'\in g(a)$. By assumption, there exists some $a'\in g(a)$ such that $f(a')=i$, and so $P(V|a',i)$ can be consistently estimated.
% \end{proof}




% \subsection{Recovering a model-selection rule}

% Given $f:X\to \mathbb{R}$, define $\text{argmin}_x f(x) = \{x: f(x)\leq f(x')\text{ for all }x'\in X\}$ (this is the standard definition, I just put it here to emphasise that argmin is a set).

% Suppose we have a loss $L_{M^*,C}:\mathcal{M}\to \mathbb{R}$  and a set of models $\mathcal{M}$ with the property that 
% \begin{align}
%     M \in \mathrm{argmin}_M L_{M^*,C}(M)\implies \mathrm{argmin}_I \mathbb{E}_{M(I)}[C(X)] = \mathrm{argmin}_I \mathbb{E}_{M^*(I)}[C(X)] \label{eq:cq_loss1}
% \end{align}
% Then proceed as in Def. \ref{def:causal_query_1} with $D$ replaced by $M^*$.

% Condition \ref{eq:cq_loss1} is too weak - could strengthen it to for every $\epsilon > 0$ there is $\delta > 0$ s.t.
% \begin{align}
%     M \in \{M:L_{M^*,C}(M) < \mathrm{min}_{M'} L_{M^*,C}(M') + \delta \}\implies \mathrm{argmin}_I \mathbb{E}_{M(I)}[C(X)] = \mathrm{argmin}_I \mathbb{E}_{M^*(I)}[C(X)] + \epsilon \label{eq:cq_loss2}
% \end{align}

% Additional complication: given $\mathcal{S}$, we may not be able to find an approximately optimal model $M$. In particular, we may not be able to bound $|L_{M^*,C}(M)-L_{\mathcal{S},C}(M)|$. ($L_{\mathcal{S}}$ needs definition here).

% \textbf{Are there alternative weaker conditions that may be desirable? Do these lead to actually-existing types of causal inference query?}

% It seems like the two things that might be desirable are, informally, policy improvement and sample complexity improvement. 

% \textbf{Weak policy improvement:} given some prior $P_\mathcal{M}$ over $M$ and $P_\mathcal{M'}$ over $M'=\text{argmin}_M L_{\mathcal{S},C}(M)$ and 
% \[I\in \mathrm{argmin}_I \mathbb{E}_{P_{M}}\left[\mathbb{E}_{M^*(I)}[C(X)]\right]\] \[I'\in \mathrm{argmin}_I \mathbb{E}_{P_{M'}}\left[\mathbb{E}_{M(I)}[C(X)]\right]\]
% weak policy improvement:
% \begin{align}
%     \mathbb{E}_{M^*(I')}[C(X)] < \mathbb{E}_{M^*(I)}[C(X)]
% \end{align}
% Note: introducing $P_\mathcal{M}$ and $P_\mathcal{M'}$ suggests replacing the loss $L$ with Bayes rule?

% \textbf{Sample complexity improvement:} suppose we have $L$ such that Eq \ref{eq:cq_loss2} holds, and there exist extra observations $\mathcal{S}_0$ such that for model class $\mathcal{M}$ w.p. $1-\delta$ we have \[|L_{M^*,C}(M)-L_{\mathcal{S}\cup\mathcal{S}_0,C}(M)|<\epsilon\]

% Suppose we have a loss $\tilde{L}_{\mathcal{S},C}$ such that for $\mathcal{M}'=\mathrm{argmin}_M L_{\mathcal{S},C}(M)$ there exist extra observations $\mathcal{S}_0'$ such that $|\mathcal{S}_0'|<|\mathcal{S}_0|$ and
% \[|L_{M^*,C}(M)-L_{\mathcal{S}\cup\mathcal{S}'_0,C}(M)|<\epsilon\]

% ** This needs a universal quantifier.

% \subsection{Inferring a causal model}

% Given data $D$ over variables $\mathbf{V}$, a class of possible causal models $\mathcal{M}$ and a $D$-dependent loss $\mathcal{L}_D:\mathcal{M}\to \mathbb{R}$, which models $M\subset \mathcal{M}$ minimise $\mathcal{L}_D$?

% Examples: Pearl, chapter 2 \cite{pearl_causality:_2009} - uses estimated distribution $\hat{P}$ rather than data $D$. Proposes two algorithms $IC$ and $IC^*$. Both output sets of CBNs with common conditional independence properties.

% $IC$ considers the class $\mathcal{M}\subset\text{CBN}$ which is the union of all causal structures that can be represented as graphs with exactly one node for each $V\in\mathbf{V}$.

% $IC^*$ considers the class that is the union of all causal structures that can be represented as graphs with one node for each $V\in\mathbf{V}$ and one common cause node for each pair of variables.


% \subsection{Predicting the effect of an intervention}

% Given data $D$ over variables $\mathbf{V}$ and intervention space $\mathcal{I}$, outcome variables $\mathbf{Y}\subset\mathbf{V}$ predictor $\hat{M}:\mathcal{I}\to\text{Range}(Y)$ and loss $\mathcal{L}_D:\hat{M}\to\mathbb{R}$, find $\hat{M}$ minimising $\mathcal{L}_D$.*

% What if we want the complete distribution over $Y$ rather than a point estimate?